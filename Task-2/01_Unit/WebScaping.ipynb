{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending GET request to https://www.shadowfox.in/#\n",
      "Response status code: 200\n",
      "Website content fetched successfully\n",
      "Data extraction completed and saved to scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# URL of the ShadowFox website\n",
    "url = \"https://www.shadowfox.in/#\"\n",
    "\n",
    "# Custom exception for website access errors\n",
    "class WebsiteAccessError(Exception):\n",
    "    pass\n",
    "\n",
    "# Function to send a GET request and handle errors\n",
    "def fetch_url(url):\n",
    "    try:\n",
    "        print(f\"Sending GET request to {url}\")\n",
    "        response = requests.get(url)\n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "        response.raise_for_status()  # Raise an exception for non-2xx status codes\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise WebsiteAccessError(f\"Error fetching URL: {e}\")\n",
    "\n",
    "# Function to extract data from the website\n",
    "def extract_data(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Extract the desired data\n",
    "    title = soup.find(\"title\").text\n",
    "\n",
    "    # Extract description and keywords from meta tags\n",
    "    description_meta = soup.find(\"meta\", {\"name\": \"description\"})\n",
    "    description = description_meta[\"content\"] if description_meta else None\n",
    "\n",
    "    keywords_meta = soup.find(\"meta\", {\"name\": \"keywords\"})\n",
    "    keywords = keywords_meta[\"content\"] if keywords_meta else None\n",
    "\n",
    "    internship_titles = [h3.text for h3 in soup.select(\"section.internship h3\")]\n",
    "\n",
    "    return title, description, keywords, internship_titles\n",
    "\n",
    "# Function to save data to a CSV file\n",
    "def save_to_csv(data, filename):\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Title\", \"Description\", \"Keywords\", \"Internship Titles\"])\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Fetch the website content\n",
    "try:\n",
    "    html_content = fetch_url(url)\n",
    "    print(\"Website content fetched successfully\")\n",
    "    # Extract data if the website content was fetched successfully\n",
    "    if html_content:\n",
    "        title, description, keywords, internship_titles = extract_data(html_content)\n",
    "        data = [(title, description, keywords, \", \".join(internship_titles))]\n",
    "        save_to_csv(data, \"scraped_data.csv\")\n",
    "        print(\"Data extraction completed and saved to scraped_data.csv\")\n",
    "    else:\n",
    "        print(\"Failed to fetch website content.\")\n",
    "except WebsiteAccessError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
